{
  "meta": {},
  "items": [
    {
      "itemID": "000",
      "menu_item": "WEB ORIGINAL:",
      "contenido": "How to Build AI Agents Using Make.com (FREE COURSE 2025)\n(Web Original):\n\nhttps://youtu.be/rfonp8KiIso?si=2Yom0s9iHaqaFzL8"
    },
    {
      "itemID": "001",
      "menu_item": "Introducción: ¿Qué es un Agente de IA y cómo funciona?",
      "contenido": "Introducción: ¿Qué es un Agente de IA y cómo funciona?:\n\nUn Agente de IA es un sistema autónomo que va más allá de un simple chatbot. No solo responde preguntas, sino que puede percibir su entorno, tomar decisiones y ejecutar acciones para alcanzar un objetivo específico. A diferencia de un chatbot que sigue un guion, un agente puede usar herramientas (como buscar en Google, realizar cálculos o consultar una base de datos) y recordar interacciones pasadas para actuar de forma más inteligente y proactiva.\n\nEn este tutorial, construiremos un agente de IA desde cero usando Make.com, una plataforma de automatización que no requiere saber programar."
    },
    {
      "itemID": "002",
      "menu_item": "Los 4 Componentes Clave de Nuestro Agente de IA",
      "contenido": "Los 4 Componentes Clave de Nuestro Agente de IA:\n\nNuestro agente se basará en cuatro pilares fundamentales que trabajarán juntos dentro de un escenario de Make.com:\n\nLa Interfaz (UI - User Interface): Es el punto de entrada por donde el usuario se comunica con el agente. Usaremos un Webhook, que es una URL única que puede recibir datos. Cualquier aplicación o formulario que pueda enviar información a esa URL servirá como interfaz.\n\nEl Cerebro (LLM - Large Language Model): Es el núcleo que procesa el lenguaje y toma decisiones. Utilizaremos el modelo GPT de OpenAI. Le daremos instrucciones (un \"prompt\") para que entienda su rol, las herramientas que tiene disponibles y cómo decidir cuál usar.\n\nLas Herramientas (Tools): Son las acciones que el agente puede realizar. En nuestro caso, crearemos herramientas sencillas como obtener la fecha y hora actual o buscar información en Google. El \"Cerebro\" decidirá cuándo y cómo usar estas herramientas.\n\nLa Memoria (Memory): Es la capacidad del agente para recordar conversaciones anteriores. Usaremos el módulo Data Store de Make.com para guardar un historial del chat y que el agente tenga contexto en cada nueva interacción."
    },
    {
      "itemID": "003",
      "menu_item": "Paso 1: Configurar el Escenario y el Punto de Entrada (Webhook)",
      "contenido": "Paso 1: Configurar el Escenario y el Punto de Entrada (Webhook):\n\nEl primer paso es crear el lienzo donde construiremos nuestro agente y definir cómo recibiremos las preguntas de los usuarios.\n\nCrea un Nuevo Escenario: En tu panel de Make.com, haz clic en \"Create a new scenario\".\n\nAñade el Módulo Webhook: Haz clic en el círculo grande y busca el módulo \"Webhooks\". Selecciónalo.\n\nConfigura el Webhook: Elige la opción \"Custom webhook\". Haz clic en \"Add\" para crear un nuevo webhook, dale un nombre descriptivo (ej. \"AgenteIA_Input\") y guarda.\n\nObtén la URL: Make.com te proporcionará una URL única. Cópiala. Esta es la dirección a la que enviaremos las preguntas del usuario. Para probarla, puedes pegarla en tu navegador y añadirle al final ?pregunta=Hola, por ejemplo: https://hook.eu1.make.com/xxxx?pregunta=Hola.\n\nEjecuta el Módulo: Haz clic en \"Run once\" en Make.com y luego accede a la URL desde tu navegador para enviar el primer dato. Esto permitirá a Make.com determinar la estructura de los datos que recibirá."
    },
    {
      "itemID": "004",
      "menu_item": "Paso 2: Implementar la Memoria con Data Store",
      "contenido": "Paso 2: Implementar la Memoria con Data Store:\n\nPara que nuestro agente recuerde conversaciones pasadas, necesitamos un lugar donde almacenarlas.\n\nAñade el Módulo Data Store: Haz clic en el signo \"+\" junto al módulo Webhook y busca \"Data Store\".\n\nSelecciona la Acción: Elige la acción \"Get a record\". Esto nos permitirá buscar el historial de una conversación existente.\n\nConfigura el Data Store:\n\nData store: Haz clic en \"Add\" para crear uno nuevo. Dale un nombre (ej. \"MemoriaAgente\") y define su estructura. Necesitaremos al menos dos campos:\n\nconversationID (Tipo: Text, márcalo como \"Key\" o clave primaria).\n\nhistory (Tipo: Text).\n\nKey: Mapea el conversationID que recibes a través del Webhook. Si no recibes uno, puedes usar un identificador único, como el ID del usuario.\n\nManejo de Errores: Si no se encuentra un historial (es la primera vez que el usuario habla), la operación fallará. Haz clic derecho en el módulo Data Store y selecciona \"Add error handler\". Conecta una ruta de error para manejar los casos donde no hay historial previo."
    },
    {
      "itemID": "005",
      "menu_item": "Paso 3: Construir el \"Cerebro\" con OpenAI",
      "contenido": "Paso 3: Construir el \"Cerebro\" con OpenAI:\n\nEste es el paso más importante. Aquí le damos al modelo de lenguaje (LLM) las instrucciones para que actúe como un agente.\n\nAñade el Módulo OpenAI: Agrega un módulo de \"OpenAI\" y selecciona la acción \"Create a Chat Completion\".\n\nConecta tu Cuenta: Si no lo has hecho, conecta tu cuenta de OpenAI usando tu API Key.\n\nConfigura el Modelo: Elige un modelo potente como gpt-4 o gpt-3.5-turbo.\n\nCrea los Mensajes (Prompt): Esta es la parte crucial. Añadiremos un mensaje de tipo \"System\" y uno de tipo \"User\".\n\nMensaje de Sistema (System): Aquí definimos la personalidad y las reglas del agente. Este es un ejemplo de prompt:\n\ncode\nCode\ndownload\ncontent_copy\nexpand_less\nEres un asistente de IA. Tu objetivo es ayudar al usuario. Tienes acceso a las siguientes herramientas:\n\n[\n  {\"name\": \"google_search\", \"description\": \"Busca información en tiempo real en Google. Úsala para preguntas sobre eventos actuales, datos específicos o cualquier cosa que no conozcas.\"},\n  {\"name\": \"get_date\", \"description\": \"Obtiene la fecha y hora actual. Úsala cuando el usuario pregunte por el día o la hora.\"}\n]\n\nCuando necesites usar una herramienta, responde ÚNICAMENTE con un objeto JSON con la clave \"tool_name\" y \"query\". Por ejemplo: {\"tool_name\": \"google_search\", \"query\": \"precio del bitcoin\"}.\n\nSi no necesitas una herramienta, responde directamente al usuario de forma normal.\n\nMensaje de Usuario (User): Aquí combinamos el historial de la conversación (obtenido del Data Store) con la nueva pregunta del usuario (obtenida del Webhook). El formato sería:\nHistorial de la conversación: [history del Data Store]. Nueva pregunta: [pregunta del Webhook].\n\nHabilitar respuesta JSON: En la configuración avanzada del módulo, activa la opción para que la respuesta del modelo sea en formato JSON. Esto facilita el procesamiento posterior."
    },
    {
      "itemID": "006",
      "menu_item": "Paso 4: El Router para Decidir la Acción",
      "contenido": "Paso 4: El Router para Decidir la Acción:\n\nEl \"Cerebro\" (OpenAI) nos dirá si necesita usar una herramienta o si puede responder directamente. Usaremos un Router para dividir el flujo de trabajo según esa decisión.\n\nAñade un Router: Después del módulo de OpenAI, añade un \"Router\". Este módulo te permite crear múltiples caminos o ramas.\n\nCrea la Primera Ruta (Usar Herramienta):\n\nConecta una ruta desde el router.\n\nHaz clic en el icono de filtro entre el router y el siguiente módulo.\n\nConfigura la condición: La respuesta del módulo de OpenAI (message.content) debe contener el texto \"tool_name\". Esto indica que el LLM ha decidido usar una herramienta.\n\nCrea la Segunda Ruta (Respuesta Directa):\n\nCrea otra ruta desde el router.\n\nEsta será la ruta por defecto (la que se toma si la primera condición no se cumple). Puedes marcar la casilla \"Fallback route\" en la configuración del filtro. Esta rama se activará cuando el LLM responda directamente sin pedir una herramienta."
    },
    {
      "itemID": "007",
      "menu_item": "Paso 5: Ejecutar las Herramientas",
      "contenido": "Paso 5: Ejecutar las Herramientas:\n\nEn la rama donde se decidió usar una herramienta, necesitamos ejecutar la acción correspondiente.\n\nParsear la Respuesta JSON: El LLM nos dio una respuesta en formato JSON. Usa el módulo \"JSON\" con la acción \"Parse JSON\" para extraer el nombre de la herramienta (tool_name) y la consulta (query).\n\nAñade otro Router (para herramientas): Después de \"Parse JSON\", añade un segundo router para seleccionar la herramienta específica.\n\nRuta para Google Search:\n\nCrea una rama y ponle un filtro donde tool_name sea igual a google_search.\n\nAñade un módulo para buscar en Google (puedes usar el módulo \"HTTP\" para hacer una petición a una API de búsqueda o un módulo específico si está disponible). Pasa el query como parámetro de búsqueda.\n\nRuta para Obtener Fecha:\n\nCrea otra rama y ponle un filtro donde tool_name sea igual a get_date.\n\nUsa el módulo de \"Tools\" y la acción \"Get current date\" o simplemente las variables de fecha de Make.com (now).\n\nEl resultado de cada una de estas herramientas (el resultado de la búsqueda o la fecha actual) será el \"contexto\" que usaremos en el siguiente paso."
    },
    {
      "itemID": "008",
      "menu_item": "Paso 6: Generar la Respuesta Final (Tras Usar una Herramienta)",
      "contenido": "Paso 6: Generar la Respuesta Final (Tras Usar una Herramienta):\n\nUna vez que la herramienta ha obtenido la información (ej. los resultados de Google), el agente no puede simplemente mostrar esos datos crudos. Debe usar su \"Cerebro\" de nuevo para formular una respuesta natural.\n\nAñade otro Módulo OpenAI: Al final de las rutas de las herramientas (puedes unirlas de nuevo con un módulo genérico si quieres), añade otro módulo \"OpenAI\" (\"Create a Chat Completion\").\n\nConfigura el Nuevo Prompt:\n\nMensaje de Sistema: \"Eres un asistente de IA. Responde a la pregunta del usuario basándote en la información proporcionada.\"\n\nMensaje de Usuario: \"La pregunta original era: '[pregunta original del Webhook]'. La información obtenida de la herramienta es: '[resultado del módulo de la herramienta]'. Por favor, formula una respuesta final para el usuario.\"\n\nLa Salida es la Respuesta Final: El resultado de este segundo módulo de OpenAI será la respuesta definitiva y bien redactada que se le entregará al usuario."
    },
    {
      "itemID": "009",
      "menu_item": "Paso 7: Actualizar la Memoria y Enviar la Respuesta",
      "contenido": "Paso 7: Actualizar la Memoria y Enviar la Respuesta:\n\nPara completar el ciclo, debemos guardar la interacción actual en la memoria y devolver la respuesta al usuario.\n\nActualizar el Data Store:\n\nAñade un módulo \"Data Store\" con la acción \"Add/replace a record\".\n\nData store: Selecciona el mismo que creaste al principio.\n\nKey: Usa el conversationID del usuario.\n\nHistory: Construye el nuevo historial. Debe contener el historial anterior, la pregunta del usuario y la respuesta final del agente. Por ejemplo: [historial anterior]\\nUsuario: [pregunta]\\nAgente: [respuesta final].\n\nEnviar la Respuesta con Webhook Response:\n\nAñade el módulo final, \"Webhooks\", y selecciona la acción \"Webhook response\".\n\nStatus: 200.\n\nBody: Aquí inserta la respuesta final generada por el agente (ya sea la de la ruta directa o la generada tras usar una herramienta).\n\nEsto enviará la respuesta de vuelta a la aplicación o formulario que originalmente llamó al webhook."
    },
    {
      "itemID": "010",
      "menu_item": "VALIDACIÓN CON FUENTES TÉCNICAS OFICIALES",
      "contenido": "VALIDACIÓN CON FUENTES TÉCNICAS OFICIALES:\n\nCada componente clave de este tutorial se basa en la funcionalidad documentada oficialmente por Make.com y OpenAI.\n\nWebhooks como Disparador (Trigger): El uso de un \"Custom Webhook\" para iniciar un escenario al recibir datos de una fuente externa es una funcionalidad estándar y documentada de Make.com.\n\nFuente: https://www.make.com/en/help/tools/webhooks\n\nRouter para Flujos Condicionales: La utilización del módulo \"Router\" para crear ramas y ejecutar diferentes acciones basadas en condiciones (como la respuesta del LLM) es el método oficial para controlar el flujo de un escenario.\n\nFuente: https://www.make.com/en/help/scenarios/scenario-editor/router\n\nData Store para Persistencia de Datos (Memoria): El módulo \"Data Store\" está diseñado específicamente para almacenar y recuperar datos entre ejecuciones de escenarios, lo que lo hace ideal para implementar la memoria del agente.\n\nFuente: https://www.make.com/en/help/tools/data-store\n\nIntegración con OpenAI: El tutorial utiliza el módulo oficial de OpenAI en Make.com. La construcción de prompts con un rol \"System\" para definir el comportamiento del modelo es una práctica recomendada por OpenAI para guiar la respuesta del LLM.\n\nFuente (Módulo Make): https://www.make.com/en/help/apps/ai/openai--dall-e---whisper-\n\nFuente (Guía de Prompts OpenAI): https://platform.openai.com/docs/guides/prompt-engineering/system-message\n\nSimulación de Uso de Herramientas (Tool Use): El método de describir herramientas en el prompt de sistema y pedir una respuesta en formato JSON es una forma de implementar la lógica de \"tool use\" o \"function calling\". OpenAI tiene una funcionalidad nativa para esto, pero el enfoque del tutorial lo simula de manera efectiva dentro de las capacidades de Make.com.\n\nFuente (Concepto en OpenAI): https://platform.openai.com/docs/guides/function-calling"
    }
  ]
}